{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# INF674 S5: Power Laws\n",
    "\n",
    "## Céline Comte & Fabien Mathieu\n",
    "\n",
    "## 2017 - 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "If you want to deepen your theoretical knowledge of power laws, you can read (this is **not** mandatory):\n",
    "- A. Barabasi and R. Albert, **Emergence of Scaling in Random Networks**.\n",
    "- Chapter 7 from the book [Epidemics and Rumours in Complex Networks][massoulie].\n",
    "- MEJ Newman, **Power laws, Pareto distributions and Zipf's law**.\n",
    "\n",
    "Other optional references are given in the course.\n",
    "\n",
    "[massoulie]: http://www.lincs.fr/wp-content/uploads/2013/01/CUP_book_final.pdf \"Epidemics and Rumours in Complex Networks by Moez Draief and Laurent Massoulié\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-30T10:39:17.701589Z",
     "start_time": "2017-10-30T10:39:17.388755Z"
    },
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import zipfile\n",
    "import gzip\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# 1. Albert-Barabási Degree distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Write a function that gives, for given $\\alpha$ and $n$, the vector of node degrees of an Albert-Barabási graph of $n$ nodes built from a graph seed $G(0)$ of two nodes linked together.\n",
    "\n",
    "*Advice 1*: Drawing proportionnally to the degree may be a computational bottleneck. Noticing that the degrees of such an Albert-Barabási graph of size $n$ sum to $2n-2$, can you build an array of size $2n-2$ such that picking a node proportionnally to its degree boils down to picking up a random uniform element of the array?\n",
    "\n",
    "*Advice 2*: The function ``bincount`` from ``numpy`` package could be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Question 2\n",
    "\n",
    "After choosing a value of $n$:\n",
    "- such that the code above runs reasonably fast (less than a dozen seconds),\n",
    "- as large as you can,\n",
    "\n",
    "Study the degree distribution (CCDF and number of nodes having specified degrees) for a few values of $\\alpha$ between $0$ and $1$. Compare the results to what you saw in course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (Bonus)\n",
    "\n",
    "What can you say specifically for the case $\\alpha = 1$ ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Power Laws on Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When doing research, it is frequent to deal with some datasets. Sometimes, you will have to produce them yourself. This is not as easy as it seems and a full course would probably only scratch the surface of the required skills. Sometimes, others have done all the heavy lifting for you, and you just need to learn how to use existing datasets for your specific needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**File Format:** The datasets are provided with the following format:\n",
    "- **_dataset_.ids** contains the actual names of the nodes (one per line, $ n $ lines in total). By convention, each node is associated to its line number (from $ 0 $ to $ n-1 $). Actual names may contain special characters (e.g. *ç*, *é*), so it is encoded with *utf-8*.\n",
    "- **_dataset_.adja** contains the adjacency list of the graph: line $ i $ (from $ 0 $ to $ n-1 $) contains, in plain ASCII, the numbers of the nodes that are neighbors of $ i $. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remind Python where your dataset files are!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-30T10:39:31.089034Z",
     "start_time": "2017-10-30T10:39:31.086653Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory = \"../Datasets/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caching results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be a burden to parse again and again the same datas from ASCII files and convert them into a proper format. The following function will be used to automatically save the variables you extract from the dataset to a more numpy-friendly format. Currently comes in two flavors:\n",
    "- using **compress = False** will store variables in uncompressed *npy* files. Very fast to read (especially if you have a SSD drive), but storage costly.\n",
    "- using **compress = True** will store variables in compressed *npy* files. Storage efficient, but CPU costly. Can be interesting in case you have a mechanic hard drive, ultra-fast CPU or storage shortage.\n",
    "\n",
    "Also note the presence of a *rebuild* flag to force the variable to be recomputed.\n",
    "\n",
    "Thanks to Pierre-Antoine (ACN 2017-2018) for hinting the approach (even if his solution based on *npz* seemed to work only on his laptop for some reason, so I had to try something else)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-30T10:39:31.105693Z",
     "start_time": "2017-10-30T10:39:31.091151Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def use_cache(builder, prefix=\"dblp\", variable = \"size\", rebuild = False, compress = False):            \n",
    "        try:\n",
    "            if rebuild:\n",
    "                raise ValueError('Value needs to be rebuilt')\n",
    "            if compress:\n",
    "                with gzip.GzipFile(directory+prefix+\"-\"+variable+\".npy.gz\", \"r\") as f:\n",
    "                    return np.load(f)\n",
    "            else:\n",
    "                return np.load(directory+prefix+\"-\"+variable+\".npy\")\n",
    "        except:\n",
    "            data = builder(prefix)\n",
    "            if compress:\n",
    "                with gzip.GzipFile(directory+prefix+\"-\"+variable+\".npy.gz\", \"w\") as f:\n",
    "                    np.save(f, data)\n",
    "            else:\n",
    "                np.save(directory+prefix+\"-\"+variable, data)\n",
    "            return data\n",
    "# Set default behavior\n",
    "compress = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the core functions below have the following behavior: first they try to load the results from an npy file if one exists, otherwise they parse the dataset to extract the information and save it in an npy file for the next use. This approach avoids re-doing the same work over and over again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function gives the number of nodes $n$ and the total number of *oriented edges* $m$ of the graph. In the case where the graph is undirected, all edges will be counted twice ($(i,j)$ and $(j,i)$ are the same edge on an undirected graph) so the actual number of edges is $\\frac m 2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-30T10:39:31.114758Z",
     "start_time": "2017-10-30T10:39:31.107115Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_size(prefix = \"dblp\"):\n",
    "    n = 0\n",
    "    m = 0\n",
    "    with zipfile.ZipFile(directory+prefix+\".zip\") as myzip:\n",
    "        with myzip.open(prefix+\".adja\") as f:\n",
    "            for line in f:\n",
    "                n += 1\n",
    "                m += len([int(s) for s in line.split()])\n",
    "    size = array([n, m])\n",
    "    return size\n",
    "\n",
    "def get_size(prefix = \"dblp\", rebuild = False):\n",
    "    return use_cache(build_size, prefix, variable = \"size\", rebuild = rebuild, compress = compress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us run this function to create the npy file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-30T10:39:31.125615Z",
     "start_time": "2017-10-30T10:39:31.116201Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix = \"dblp\"\n",
    "n, m = get_size(prefix)\n",
    "print(\"Number of nodes in %s: %s\" % (prefix, n))\n",
    "print(\"Number of edges in %s: %s\" % (prefix, m//2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjacency List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A natural way to store the adjacency list would be to use an array (or list) of arrays (or lists), such that A[i][j] would refer to the $j$th neighbor of node $i$. In practice, this structure can have some memory usage overhead, so we will store the adjacency list in a flat array with the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-30T10:39:31.137895Z",
     "start_time": "2017-10-30T10:39:31.127400Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_adjacency(prefix = \"dblp\"):\n",
    "    n, m = get_size(prefix)\n",
    "    A = zeros(n+m+1, dtype = int)\n",
    "    A[0] = n+1 # Don't forget the +1!!!\n",
    "    with zipfile.ZipFile(directory+prefix+\".zip\") as myzip:\n",
    "        with myzip.open(prefix+\".adja\") as f:\n",
    "            i = 0\n",
    "            for line in f:\n",
    "                neighbors = array(line.split(), dtype = int)\n",
    "                A[i+1] = A[i]+len(neighbors)\n",
    "                A[A[i]:A[i+1]] = neighbors\n",
    "                i += 1\n",
    "    return A\n",
    "\n",
    "def get_adjacency(prefix = \"dblp\", rebuild = False):\n",
    "    return use_cache(build_adjacency, prefix, variable = \"adjacency\", rebuild = rebuild, compress = compress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load $A$ in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-30T10:39:31.691004Z",
     "start_time": "2017-10-30T10:39:31.142264Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = get_adjacency(\"dblp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result, *A*, is a numpy array of integer of size $n+m+1$, organized as follows:\n",
    "- The first $n+1$ values are indices\n",
    "- The last $m$ values are destinations\n",
    "- The neighbors of node $i$ are stored in A[A[i]:A[i+1]], for each $i = 0,\\ldots,n-1$\n",
    "\n",
    "The following function just return the neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-30T10:39:31.695018Z",
     "start_time": "2017-10-30T10:39:31.692445Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neighbors(A, index):\n",
    "    return A[A[index]:A[index+1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, just use A[A[i]:A[i+1]] if you can, it avoids calling a function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index / Name conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the functions above assume a node is represented by an integer $0\\leq i<n$, but researchers, Wikipedia pages, and even actors have names! Let us write some functions to translate integers to names and *vice versa*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-30T10:39:31.710054Z",
     "start_time": "2017-10-30T10:39:31.696955Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_ids(prefix = \"dblp\"):\n",
    "    n, m = get_size(prefix)\n",
    "    delimiter = zeros(n+1, dtype = int)\n",
    "    text = \"\"\n",
    "    with zipfile.ZipFile(directory+prefix+\".zip\") as myzip:\n",
    "        with myzip.open(prefix+\".ids\") as f:\n",
    "            i = 0\n",
    "            for line in codecs.iterdecode(f, 'utf8'):\n",
    "                delimiter[i+1] = delimiter[i]+len(line)-1\n",
    "                text += line[0:-1]\n",
    "                i += 1\n",
    "    return [delimiter, text]\n",
    "    \n",
    "def get_ids(prefix = \"dblp\", rebuild = False):\n",
    "    return use_cache(build_ids, prefix, variable = \"ids\", rebuild = rebuild, compress = compress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function above returns a *delimiter* array of size $n+1$ and a *text* string that concatenates all researcher names. It uses the same principle used for the adjacency list: the name of a researcher associated to number $i$ is text[delimiter[i]:delimiter[i+1]]. This allows us to do the conversion from name to index, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-30T10:39:31.716997Z",
     "start_time": "2017-10-30T10:39:31.712376Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def index2name(index, prefix = \"dblp\", delimiter = None, text = None):\n",
    "    if delimiter is None:\n",
    "        delimiter, text = get_ids(prefix)\n",
    "    return text[delimiter[index]:delimiter[index+1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-30T10:39:31.723398Z",
     "start_time": "2017-10-30T10:39:31.718409Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def name2index(name, prefix = \"dblp\", delimiter = None, text = None):\n",
    "    try:\n",
    "        if delimiter is None:\n",
    "            delimiter, text = get_ids(prefix)\n",
    "        offset = text.index(name)\n",
    "        return where(delimiter == offset)[0][0]\n",
    "    except:\n",
    "        print(\"Name not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try with some names. Note that the first execution will build the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-30T10:39:32.014952Z",
     "start_time": "2017-10-30T10:39:31.725064Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name2index(\"Paul_Erdös\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-30T10:39:32.268596Z",
     "start_time": "2017-10-30T10:39:32.016068Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name2index(\"Fabien_Mathieu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-30T10:39:32.514644Z",
     "start_time": "2017-10-30T10:39:32.269789Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index2name(711561)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-30T10:39:32.778470Z",
     "start_time": "2017-10-30T10:39:32.515859Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index2name(149114)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remark: the **name2index** function is very rough: it just try to match *name* as a substring of *text* and find the corresponding index in the delimiter array. It is quite slow and may fail if the name of a researcher is a substring of the name of another researcher, but it will be enough for this practical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets will be given on a USB key. This practical assumes they are stored in **../Datasets/** relatively to your working directory (adjust according to your own organization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBLP dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBLP (*DataBase systems and Logic Programming* or *Digital Bibliography & Library Project*) is THE database that records CS publications. It records authors, conferences, journals... It is a good entry point to study a good example of undirected small-world: the co-authorship graph.\n",
    "\n",
    "There are multiple versions of the DBLP graph available. For this practical, we will focus on the one available in http://konect.uni-koblenz.de/networks/dblp_coauthor\n",
    "\n",
    "Let us begin with a simple example on how to compute the size of the Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (Easy)\n",
    "\n",
    "Write a function that returns the degrees of a dataset, i.e. the number of neighbors in the adjacency list for each node (in an array). For directed graphs, the function will return the *out*-degrees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Write a function that gives the degree distribution. For example, it may return an array ``deg_dist`` such that the number of nodes that have degree $i$ is ``deg_dist[i-1]``. Display the degree distribution in a loglog scale. Also display the Complentary Cumulative Distribution Function of the degree. Comment the results in view of the previous parts of this practical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redo question 2 for IMDB dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia dataset\n",
    "\n",
    "We now play with French and English crawls of Wikipedia made in 2013 and available on http://webgraph.di.unimi.it/. The graphs have been *cleaned*: only links from one article to another article are kept.\n",
    "\n",
    "Two main differences with the DBLP/IMDB databases you have just dealt with:\n",
    "- The graphs are now *oriented*: a link from $i$ to $j$ does not mean there is a link from $j$ to $i$.\n",
    "- The graphs are bigger. If you didn't optimize your code for DBLP, you will probably have to here. \n",
    "\n",
    "The French crawl is made of three files:\n",
    "- **frwiki-2013.ids** contains the article titles (one per line, $ n $ lines in total). By convention, each article is associated with its line number (from $ 0 $ to $ n-1 $).\n",
    "- **frwiki-2013.adja** contains the adjacency list of the graph: line $ i $ (from $ 0 $ to $ n-1 $) contains, in plain ASCII, the numbers of the articles that are linked by $ i $. \n",
    "- **frwiki-2013-t.adja** contains the adjacency list of the transposed graph: line $ i $ (from $ 0 $ to $ n-1 $) contains the numbers of the articles that have a link to $ i $.\n",
    "\n",
    "The English crawl is provided in a similar way, with the prefix **enwiki-2013** instead of **frwiki-2013**. Note that it is roughly three times bigger than the French crawl. Feel free to use the dataset(s) you want.\n",
    "\n",
    "The questions are essentially the same as for the DBLP dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Give the number of nodes and edges of the dataset(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "Display in a loglog scale the degree distribution(s). Comment the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Cryptocurrency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A friend of yours sends the following link to you:\n",
    "https://medium.com/@jamiecopeland_52423/zipfian-distribution-of-cryptocurrency-market-capitalizations-649bf31e2fb8\n",
    "\n",
    "As you are now a specialist in power law matters, he asks your opinion. What should you answer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "nav_menu": {},
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
